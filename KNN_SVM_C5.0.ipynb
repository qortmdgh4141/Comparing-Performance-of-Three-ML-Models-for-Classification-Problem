{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONSi43gMtvsYYsgR9ohFXm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qortmdgh4141/Classifying_Wines_by_Quality_Using_Machine_Learning/blob/main/KNN_SVM_C5.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAvvs4BQXiEn"
      },
      "outputs": [],
      "source": [
        "# sklearn 패키지에서 와인 데이터 세트를 사용하기 위해 load_wine 설정\n",
        "# 표준화를 위해 StandaradScaler 설정\n",
        "# 학습용과 테스트 데이터 분리를 위해 train_test_split 설정\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "data = load_wine(as_frame = True)"
      ],
      "metadata": {
        "id": "LN02WopeaIjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 프레임 출력 \n",
        "# 데이터를 출력함으로써 개략적인 수치를 확인 \n",
        "print(data.frame)"
      ],
      "metadata": {
        "id": "HQjRR1Ksb_Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력 부분과 목표 값을 출력 \n",
        "# 데이터의 입력 부분과 목표 변수 부분으 나누어 출력함으로써 개략적인 수치를 확인 \n",
        "print(data.data)\n",
        "print(data.target)"
      ],
      "metadata": {
        "id": "iLNtsFrTcURI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 세트 개요\n",
        "# 각 열별 최대 및 최소 분포를 파악\n",
        "print(data.DESCR)"
      ],
      "metadata": {
        "id": "nOYTujuFc1vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 프레임의 특성(feature) 이름과 목표 변수(target) 이름\n",
        "# 목표 변수에서 순서대로 'class_0'는 0, 'class_1'은 1, 'class_2'은 2을 의미\n",
        "print(\"[ 데이터 프레임의 특성(feature) ]\")\n",
        "for feature in data.feature_names:\n",
        "    print(f' - {feature}')\n",
        "print(\"\\n [ 데이터 프레임의 목표 변수(target) ]\")\n",
        "for target in data.target_names:\n",
        "    print(f' - {target}')"
      ],
      "metadata": {
        "id": "1tbeOD50elnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# random_state = 자신의 생일로 설정 => 07월 23일 => 0723 => 723\n",
        "# data 부분을 8:2 비율로 x_train과 x_test로 나눔\n",
        "# target 부분을 8:2 비율로 y_train과 y_test로 나눔\n",
        "# 학습용과 테스트 데이터 분리\n",
        "x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=723)"
      ],
      "metadata": {
        "id": "mGJpZGvBiRaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 피처 스케일링 : 학습 데이터 \n",
        "# 학습 데이터의 입력 데이터를 각 열별로 표준화\n",
        "scaler_x = StandardScaler()\n",
        "scaler_x.fit(x_train)\n",
        "x_train_std = scaler_x.transform(x_train)\n",
        "\n",
        "# 피처 스케일링 : 테스트 데이터 \n",
        "# 학습 데이터의 표준화 스케일을 사용해 테스트 데이터를 표준화\n",
        "x_test_std = scaler_x.transform(x_test)"
      ],
      "metadata": {
        "id": "5Ih5Pv0kmhgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN 분류를 위해 KNeighborsClassifier 설정\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "## 최근접 이웃 수 결정\n",
        "# 학습용 데이터의 분류 정확도\n",
        "knn_train_accuracy = []\n",
        "# 테스트 데이터의 분류 정확도\n",
        "knn_test_accuracy = []\n",
        "# 최근접 이웃의 수(k) \n",
        "# -> k가 너무 작으면 데이터의 노이즈 성분까지 고려하는 과대적합(overfitting) 문제가 발생, \n",
        "# -> 반대로 k를 너무 크게 하면 결정함수가 너무 과하게 평탄화(oversmoothing)되는 문제가 발생\n",
        "# -> 최적의 K 값을 찾는것이 중요!\n",
        "\n",
        "# num_neighbors : 최적의 최근접 이웃의 수(k)을 찾기 위한 후보 숫자\n",
        "# k를 1~101의 범위에서 찾아봄 \n",
        "num_neighbors = range(1, 101)\n",
        "for k in num_neighbors:\n",
        "    # 모형화\n",
        "    # 유사도 측정 지표(metric)은 유클리드 거리, 맨하탄 거리, 민코브스킨 거리 중 유클리드 거리로 선정\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, metric='euclidean')\n",
        "    # 학습\n",
        "    knn.fit(x_train_std, y_train)\n",
        "    # 학습 데이터의 분류 정확도\n",
        "    score = knn.score(x_train_std, y_train) # 학습 모형에 의한 학습 데이터의 분류 정확도 값\n",
        "    knn_train_accuracy.append(score) # 후보 k 값에 따른 학습 데이터의 분류 정확도 값 추가\n",
        "    # 테스트 데이터의 분류 정확도\n",
        "    score = knn.score(x_test_std, y_test) # 학습 모형에 의한 테스트 데이터의 분류 정확도 값\n",
        "    knn_test_accuracy.append(score) # 후보 k 값에 따른 테스트 데이터의 분류 정확도 값 추가\n",
        "\n",
        "# 후보 k의 값에 따른 정확도를 비교\n",
        "# k 값이 80보다 커질 수록 과대적합(overfitting)&평탄화(oversmoothing) 문제 등이 발생!\n",
        "# 최적의 k 값은 5로 선정!\n",
        "max_accuracy = 0\n",
        "for num_k, accuracy in enumerate(knn_test_accuracy):\n",
        "    if max_accuracy < accuracy :\n",
        "        max_accuracy = accuracy\n",
        "        best_k = num_k+1\n",
        "print(f\"최적의 k 값 : {best_k}\")  \n",
        "print(f'최적의 k 값의 정확도 : {max_accuracy} \\n') \n",
        "\n",
        "plt.plot(num_neighbors, knn_train_accuracy, label=\"train\")\n",
        "plt.plot(num_neighbors, knn_test_accuracy, label=\"test\")\n",
        "plt.xlabel(\"K\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lY-uP09BnfaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN 분류를 위해 KNeighborsClassifier 설정\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# 모형화 : k는 5로 설정\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "# 학습\n",
        "knn.fit(x_train_std, y_train)"
      ],
      "metadata": {
        "id": "Yw2k5uPawXhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN 학습된 모형으로 테스트 데이터를 분류했을때의 정확도 (k를 5로 설정)\n",
        "knn_test_acuaracy = knn.score(x_test_std, y_test)\n",
        "print(f'KNN 알고리즘을 이용한 분류 정확도 {round(knn_test_acuaracy*100, 2)}%')"
      ],
      "metadata": {
        "id": "ZRD5DFrS0voa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 분류를 위해 svm 설정\n",
        "from sklearn import svm\n",
        "\n",
        "# SVM 분류 모형화 : 선형분리\n",
        "clf = svm.SVC(kernel='linear')\n",
        "# 모형 학습\n",
        "clf.fit(x_train_std, y_train)"
      ],
      "metadata": {
        "id": "cyvInG7225z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM 학습된 모형으로 테스트 데이터를 분류했을때의 정확도 (k를 5로 설정)\n",
        "svm_test_acuaracy = clf.score(x_test_std, y_test)\n",
        "print(f'SVM 알고리즘을 이용한 분류 정확도 {round(svm_test_acuaracy*100, 2)}%')"
      ],
      "metadata": {
        "id": "aZbNxV1T5xxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C5.0 분류를 위해 tree 설정\n",
        "# C5.0 학습 후에 테스트 데이터에 대한 예측값과 실제값의 정확도를 평가하기 위해\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# C5.0 모형화 : 입력변수에 의한 목표변수의 평가지표는 'entropy'로 설정\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "# 모형 학습 \n",
        "# 참고로 C5.0 알고리즘은 학습 데이터의 피처 스케일링을 할 필요가 없음 \n",
        "# 반대로, KNN 알고리즘 & SVM 알고리즘은 학습 데이터의 피처 스케일링이 필요)\n",
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "FmlaskYw6Q93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습된 모형을 그래프로 출력\n",
        "# 뿌리 마디에서 41 ('class_0' : 47, 'class_1': 56, 'class_2' : 39)로 구성된 \n",
        "# 총 142개 종류의 와인이 분류되는 과정이 나타남\n",
        "# 주어진 학습 데이터 세트로는 끝 마디가 모두 하나의 와인 종류로 분류되고 엔트로피가 0이 됨\n",
        "plt.figure(figsize=(15, 12))\n",
        "tree.plot_tree(clf)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-UcJQcZl-DN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C5.0 학습된 모형으로 테스트 데이터를 분류했을때의 정확도 \n",
        "# 참고로 C5.0 알고리즘은 테스트 데이터의 피처 스케일링을 할 필요가 없음 \n",
        "# 반대로, KNN 알고리즘 & SVM 알고리즘은 테스트 데이터의 피처 스케일링이 필요)\n",
        "\n",
        "y_pred = clf.predict(x_test)\n",
        "print(f'C5.0 알고리즘을 이용한 분류 정확도 {round(accuracy_score(y_test, y_pred)*100, 2)}%')"
      ],
      "metadata": {
        "id": "COifh6pb_880"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}